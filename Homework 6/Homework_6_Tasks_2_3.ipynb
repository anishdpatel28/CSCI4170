{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2:  \n",
        "We discussed how we can formulate RL problems as an MDP. Describe any\n",
        "real-world application that can be formulated as an MDP. Describe the state space, action space, transition model, and rewards for that problem. You do not need to be precise in the description of the transition model and reward (no formula is needed). Qualitative description is enough."
      ],
      "metadata": {
        "id": "KJpnXSZPH5gf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One real world application that can be formulated as an MDP is navigation for autonomous vehicles.\n",
        "\n",
        "**state space:** position of car, speed, sensor readings (like camera inputs), obstacles nearby, traffic signals  \n",
        "**action space:** accelerating, braking, turning, staying in lane  \n",
        "**transition model:** State changes based on actions such as how accelerating increases speed and changes the position of car based on direction  \n",
        "**rewards:** Positive rewards given for reaching destination quickly, without collisions. Negative rewards are given for collisions, abrupt movement, violating traffic  "
      ],
      "metadata": {
        "id": "cu7zcyhkIC5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3 (RL in Trading)"
      ],
      "metadata": {
        "id": "Wq17cyuUJN0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In trading we want to maximize the return by looking at what is the best time to buy sell and hold shares.  \n",
        "Here is defining the MDP for trading:  \n",
        "**state space:** Historical price data, indicators such as moving aaverages and portfolio status  \n",
        "**action space:** Buy, sell, hold assets  \n",
        "**transition model:** Determined by the market dynamics - next state after action is taken determined by the changing of the price and impact on the portfolio  \n",
        "**rewards:** Rewards based on profit / loss after each trade - this also factors the costs of the transitions  "
      ],
      "metadata": {
        "id": "l9KJ8texJgTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One example I found was from the following repository:  \n",
        "https://github.com/AI4Finance-Foundation/FinRL  \n",
        "\n",
        "This project uses many RL algorithms like DDPG, PPO, and A2C and creates a trading environment for simulation. This repo uses prebuilt market datasets such as Yahoo Finance dataset and Binance and uses Backtesting engine for evaluating strategies. Jupyter notebook is also used for quick testing."
      ],
      "metadata": {
        "id": "BAOQdcmhLG4l"
      }
    }
  ]
}