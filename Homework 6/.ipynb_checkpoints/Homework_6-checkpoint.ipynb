{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaIVLSF7WO-F"
   },
   "source": [
    "I will use the cnn / dailymail dataset  \n",
    "This has news articles with the corresponding highlights that act as summaries  \n",
    "There are over 300,000 articles, each entry has an article and corresponding highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CWVry_DYn0F",
    "outputId": "dd76ff01-9f73-4b44-ceda-e53e5e2e9d28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/anish/miniconda3/lib/python3.9/site-packages (3.5.0)\n",
      "Requirement already satisfied: transformers in /Users/anish/miniconda3/lib/python3.9/site-packages (4.50.3)\n",
      "Requirement already satisfied: evaluate in /Users/anish/miniconda3/lib/python3.9/site-packages (0.4.3)\n",
      "Requirement already satisfied: torch in /Users/anish/miniconda3/lib/python3.9/site-packages (2.6.0)\n",
      "Requirement already satisfied: fsspec[http]<=2024.12.0,>=2023.1.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /Users/anish/miniconda3/lib/python3.9/site-packages (from datasets) (3.11.14)\n",
      "Requirement already satisfied: pandas in /Users/anish/miniconda3/lib/python3.9/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/anish/miniconda3/lib/python3.9/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/anish/miniconda3/lib/python3.9/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/anish/miniconda3/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/anish/miniconda3/lib/python3.9/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/anish/miniconda3/lib/python3.9/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from datasets) (0.30.1)\n",
      "Requirement already satisfied: filelock in /Users/anish/miniconda3/lib/python3.9/site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: packaging in /Users/anish/miniconda3/lib/python3.9/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/anish/miniconda3/lib/python3.9/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/anish/miniconda3/lib/python3.9/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/anish/miniconda3/lib/python3.9/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/anish/miniconda3/lib/python3.9/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/anish/miniconda3/lib/python3.9/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in /Users/anish/miniconda3/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: networkx in /Users/anish/miniconda3/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/anish/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/anish/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/anish/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anish/miniconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anish/miniconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anish/miniconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anish/miniconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/anish/miniconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/anish/miniconda3/lib/python3.9/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/anish/miniconda3/lib/python3.9/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/anish/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers evaluate torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "psRVoxgnjxQj"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tewkf4e-kGAP",
    "outputId": "537d06b1-8516-4857-eb2e-65a4d5bb0f0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 287113\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 13368\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 11490\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PZyZaY9TfOLB"
   },
   "outputs": [],
   "source": [
    "subset_train = dataset[\"train\"].shuffle(seed=42).select(range(2000))\n",
    "subset_validation = dataset[\"validation\"].shuffle(seed=42).select(range(200))\n",
    "\n",
    "data = DatasetDict({\"train\": subset_train, \"validation\": subset_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1Cd5kVjAkTg-"
   },
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "max_input_length = 1024\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples[\"article\"]\n",
    "    targets = examples[\"highlights\"]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tppb7hhhfXnj"
   },
   "outputs": [],
   "source": [
    "tokenized_data = data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AtKtkWcTgarR",
    "outputId": "667d88f1-fafd-4b22-a61a-04503759f8fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in /Users/anish/miniconda3/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in /Users/anish/miniconda3/lib/python3.9/site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/anish/miniconda3/lib/python3.9/site-packages (from rouge_score) (2.0.2)\n",
      "Requirement already satisfied: absl-py in /Users/anish/miniconda3/lib/python3.9/site-packages (from rouge_score) (2.2.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Users/anish/miniconda3/lib/python3.9/site-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: joblib in /Users/anish/miniconda3/lib/python3.9/site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/anish/miniconda3/lib/python3.9/site-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: click in /Users/anish/miniconda3/lib/python3.9/site-packages (from nltk->rouge_score) (8.0.4)\n",
      "Requirement already satisfied: transformers in /Users/anish/miniconda3/lib/python3.9/site-packages (4.50.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/anish/miniconda3/lib/python3.9/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/anish/miniconda3/lib/python3.9/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/anish/miniconda3/lib/python3.9/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: filelock in /Users/anish/miniconda3/lib/python3.9/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/anish/miniconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/anish/miniconda3/lib/python3.9/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: requests in /Users/anish/miniconda3/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/anish/miniconda3/lib/python3.9/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/anish/miniconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anish/miniconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anish/miniconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anish/miniconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anish/miniconda3/lib/python3.9/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (1.5.2)\n",
      "Requirement already satisfied: pyyaml in /Users/anish/miniconda3/lib/python3.9/site-packages (from accelerate>=0.26.0) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from accelerate>=0.26.0) (24.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from accelerate>=0.26.0) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from accelerate>=0.26.0) (0.30.1)\n",
      "Requirement already satisfied: psutil in /Users/anish/miniconda3/lib/python3.9/site-packages (from accelerate>=0.26.0) (5.9.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/anish/miniconda3/lib/python3.9/site-packages (from accelerate>=0.26.0) (0.5.3)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Users/anish/miniconda3/lib/python3.9/site-packages (from accelerate>=0.26.0) (2.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/anish/miniconda3/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/anish/miniconda3/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.12.2)\n",
      "Requirement already satisfied: filelock in /Users/anish/miniconda3/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.12.0)\n",
      "Requirement already satisfied: requests in /Users/anish/miniconda3/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: jinja2 in /Users/anish/miniconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.2)\n",
      "Requirement already satisfied: networkx in /Users/anish/miniconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.2.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/anish/miniconda3/lib/python3.9/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/anish/miniconda3/lib/python3.9/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anish/miniconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anish/miniconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anish/miniconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anish/miniconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (1.26.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score\n",
    "!pip install --upgrade transformers\n",
    "!pip install --upgrade \"accelerate>=0.26.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMvNSGcz5Afd",
    "outputId": "3a2fa5af-68a7-4707-d2ca-9f5ba0568502"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anish/miniconda3/lib/python3.9/site-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9083674813476489cfa0c66d00aa5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91b0a5b7fe84e348b1f63e01be26158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502a42dfcb43413f8dad83530bda2f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53cedf70cd043758947019770f543c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/pq5vf3ts16x6jt7g3y6hrlcc0000gn/T/ipykernel_24887/3105905880.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "fp16 mixed precision requires a GPU (not 'mps').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xx/pq5vf3ts16x6jt7g3y6hrlcc0000gn/T/ipykernel_24887/3105905880.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m trainer = Seq2SeqTrainer(\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mpreprocess_logits_for_metrics\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     ):\n\u001b[0;32m---> 73\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_accelerator_and_postprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;31m# memory metrics - must set up as early as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcreate_accelerator_and_postprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5137\u001b[0m         \u001b[0;31m# create accelerator object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5138\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAccelerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5139\u001b[0m         \u001b[0;31m# some Trainer classes need to use `gather` instead of `gather_for_metrics`, thus we store a flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_for_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, device_placement, split_batches, mixed_precision, gradient_accumulation_steps, cpu, dataloader_config, deepspeed_plugin, fsdp_plugin, torch_tp_plugin, megatron_lm_plugin, rng_types, log_with, project_dir, project_config, gradient_accumulation_plugin, step_scheduler_with_optimizer, kwargs_handlers, dynamo_backend, dynamo_plugin, deepspeed_plugins)\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0;34m\"sdaa\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             ) or is_torch_xla_available(check_is_tpu=True):\n\u001b[0;32m--> 547\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"fp16 mixed precision requires a GPU (not {self.device.type!r}).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_grad_scaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: fp16 mixed precision requires a GPU (not 'mps')."
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./bart-finetuned-news\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    bf16=True\n",
    ")\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result_rouge = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result_bleu = bleu.compute(predictions=[pred.split() for pred in decoded_preds],\n",
    "                               references=[[ref.split()] for ref in decoded_labels])\n",
    "    result = {**result_rouge, **result_bleu}\n",
    "    return result\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "v3_fK-bWTyCZ",
    "outputId": "e9672b2b-8491-49f4-e258-1bbcb4ab87b5"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TnLW1XT1VvA3"
   },
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
